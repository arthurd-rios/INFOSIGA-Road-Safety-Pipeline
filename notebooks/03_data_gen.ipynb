{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "8c9ea584",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a51585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lendo o arquivo de dados processados\n",
    "\n",
    "df = pd.read_csv('../data_processed/data_processed.csv', sep=',', encoding='latin1', low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a97c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['logradouro', 'municipio', 'latitude', 'longitude', 'tipo_registro',\n",
       "       'turno', 'tp_sinistro_primario', 'qtd_gravidade_fatal',\n",
       "       'qtd_gravidade_grave', 'qtd_gravidade_leve', 'qtd_caminhao',\n",
       "       'qtd_motocicleta', 'qtd_automovel', 'qtd_pedestre', 'qtd_bicicleta',\n",
       "       'qtd_onibus', 'qtd_veic_outros', 'qtd_veic_nao_disponivel',\n",
       "       'concessionaria', 'numero_logradouro', 'tp_sinistro_atropelamento',\n",
       "       'tp_sinistro_colisao_frontal', 'tp_sinistro_colisao_lateral',\n",
       "       'tp_sinistro_colisao_transversal', 'tp_sinistro_colisao_outros',\n",
       "       'tp_sinistro_choque', 'tp_sinistro_capotamento',\n",
       "       'tp_sinistro_engavetamento', 'tp_sinistro_tombamento',\n",
       "       'tp_sinistro_outros', 'data_hora', 'hora', 'mes', 'dia_semana',\n",
       "       'indice_severidade', 'feriado', 'geometry', 'id', 'motorway', 'oneway',\n",
       "       'lanes', 'maxspeed', 'bridge', 'dist_imprecisao'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando as colunas existentes\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad9c0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo a variável alvo como 1 para os dados de acidentes reais\n",
    "\n",
    "df['target'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b0ece9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo colunas desnecessárias para a geração de dados\n",
    "\n",
    "columns_drop = ['municipio', 'tipo_registro', 'turno', 'tp_sinistro_primario', 'qtd_gravidade_fatal', \n",
    "                'qtd_gravidade_grave', 'qtd_gravidade_leve', 'qtd_caminhao', 'qtd_motocicleta', 'qtd_automovel', 'qtd_pedestre', \n",
    "                'qtd_bicicleta', 'qtd_onibus', 'qtd_veic_outros', 'qtd_veic_nao_disponivel', 'numero_logradouro', 'tp_sinistro_atropelamento',\n",
    "                'tp_sinistro_colisao_frontal', 'tp_sinistro_colisao_lateral', 'tp_sinistro_colisao_transversal', 'tp_sinistro_colisao_outros', \n",
    "                'tp_sinistro_choque', 'tp_sinistro_capotamento', 'tp_sinistro_engavetamento', 'tp_sinistro_tombamento', 'tp_sinistro_outros', \n",
    "                'data_hora', 'geometry', 'id', 'dist_imprecisao']\n",
    "\n",
    "df = df.drop(axis = 1, columns = columns_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d58ce3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['logradouro', 'latitude', 'longitude', 'concessionaria', 'hora', 'mes',\n",
       "       'dia_semana', 'indice_severidade', 'feriado', 'motorway', 'oneway',\n",
       "       'lanes', 'maxspeed', 'bridge', 'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conferindo as colunas restantes\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20288dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertendo o dataframe para GeoDataFrame e ajustando projeção\n",
    "\n",
    "geometry = gpd.points_from_xy(df['longitude'], df['latitude'])\n",
    "\n",
    "gdf = gpd.GeoDataFrame(df, geometry=geometry)\n",
    "\n",
    "gdf.set_crs(epsg=4326, inplace=True)\n",
    "\n",
    "gdf = gdf.to_crs(epsg=31983)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757704be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um buffer de 2km ao redor dos pontos de acidente\n",
    "\n",
    "gdf['geometry'] = gdf.buffer(distance=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b7a27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arthur Rios\\AppData\\Local\\Temp\\ipykernel_6048\\4123187060.py:1: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  area_mask = gdf['geometry'].unary_union\n"
     ]
    }
   ],
   "source": [
    "# Unificando os buffers para criar uma máscara de área de interesse\n",
    "\n",
    "area_mask = gdf['geometry'].unary_union\n",
    "\n",
    "area_mask = area_mask.simplify(tolerance=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fbed3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando a malha viária do arquivo parquet\n",
    "\n",
    "columns_parquet = ['geometry', 'highway', 'oneway', 'lanes', 'maxspeed', 'bridge']\n",
    "\n",
    "geodf = gpd.read_parquet('../data_processed/final_map_sp.parquet', columns=columns_parquet)\n",
    "\n",
    "geodf = geodf.to_crs(epsg=31983)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a273f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recortando a malha viária usando a máscara da área de interesse\n",
    "\n",
    "geodf = gpd.clip(geodf, mask=area_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f675daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrando para manter apenas rodovias principais\n",
    "\n",
    "mask = (geodf['highway'] == 'tertiary') | (geodf['highway'] == 'secondary') | (geodf['highway'] == 'primary')\n",
    "\n",
    "geodf = geodf[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61050f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48629      372.725814\n",
       "48628      370.977005\n",
       "63361     2067.424263\n",
       "48627     2063.065474\n",
       "141890    1204.413273\n",
       "             ...     \n",
       "183296     140.665015\n",
       "183298     167.433652\n",
       "183297     141.558665\n",
       "151695     433.161071\n",
       "165947     123.835585\n",
       "Length: 8491, dtype: float64"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculando o comprimento de cada segmento de rodovia\n",
    "\n",
    "geodf['geometry'].length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c50c95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo probabilidades de amostragem baseadas no comprimento\n",
    "\n",
    "geometry_lenghts = geodf['geometry'].length\n",
    "\n",
    "probability = geometry_lenghts/geometry_lenghts.sum()\n",
    "probability = probability/probability.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93905f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizando amostragem aleatória ponderada dos segmentos\n",
    "\n",
    "index_list = np.random.choice(\n",
    "    a=geodf.index.values,\n",
    "    size=73000,\n",
    "    replace=True,\n",
    "    p=probability\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8430288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando novo dataframe com os segmentos selecionados\n",
    "\n",
    "newdf = geodf.loc[index_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bfc76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando pontos aleatórios ao longo dos segmentos selecionados\n",
    "\n",
    "points = np.random.rand(73000)\n",
    "\n",
    "newdf['geometry'] = newdf['geometry'].interpolate(points, normalized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46ded9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo a variável alvo como 0 para os dados sintéticos\n",
    "\n",
    "newdf['target'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67c377e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo índice de severidade zero para os não-acidentes\n",
    "\n",
    "newdf['indice_severidade'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079fcd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo probabilidades para os dias da semana baseada no fluxo\n",
    "\n",
    "days_probability = [0.14, 0.14, 0.14, 0.14, 0.17, 0.13, 0.14]\n",
    "\n",
    "days_list = np.random.choice(\n",
    "    a=[0, 1, 2, 3, 4, 5, 6],\n",
    "    size=73000,\n",
    "    replace=True,\n",
    "    p=days_probability\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b223f401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atribuindo dias da semana aleatórios baseados na probabilidade\n",
    "\n",
    "newdf['dia_semana'] = days_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa88dcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo probabilidades para os meses do ano baseada na fluxo\n",
    "\n",
    "months_probability = np.array([0.100, 0.077, 0.077, 0.077, 0.077, 0.077, 0.100, 0.077, 0.077, 0.077, 0.077, 0.100])\n",
    "months_probability = months_probability / months_probability.sum()\n",
    "\n",
    "months_list = np.random.choice(\n",
    "    a=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],\n",
    "    size=73000,\n",
    "    replace=True,\n",
    "    p=months_probability\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febf3afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atribuindo meses aleatórios\n",
    "\n",
    "newdf['mes'] = months_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09829419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo probabilidade para feriados (com base na razão de números de feriados por dias do ano)\n",
    "\n",
    "holiday_probability = [0.96, 0.04]\n",
    "\n",
    "holiday_list = np.random.choice(\n",
    "    a=[0, 1],\n",
    "    size=73000,\n",
    "    replace=True,\n",
    "    p=holiday_probability\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edad046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atribuindo flag de feriado aleatoriamente\n",
    "\n",
    "newdf['feriado'] = holiday_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072bea32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo probabilidades para as horas do dia baseadas no fluxo\n",
    "\n",
    "hours_probability = [0.01, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.06, 0.06, 0.06, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, \n",
    "                     0.05, 0.06, 0.06, 0.06, 0.05, 0.05, 0.05, 0.01]\n",
    "\n",
    "hours_list = np.random.choice(\n",
    "    a=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23],\n",
    "    size=73000,\n",
    "    replace=True,\n",
    "    p=hours_probability\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0611c8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atribuindo horas aleatórias\n",
    "\n",
    "newdf['hora'] = hours_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7ba7d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "highway\n",
       "motorway    62034\n",
       "trunk       10966\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando a distribuição dos tipos de rodovia nos dados gerados\n",
    "\n",
    "newdf['highway'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a351aa31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "oneway\n",
       "yes     70531\n",
       "no       2000\n",
       "None      469\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando a distribuição de mão única\n",
    "\n",
    "newdf['oneway'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065029e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lanes\n",
       "2       51890\n",
       "3       12755\n",
       "4        3504\n",
       "None     2258\n",
       "5        1428\n",
       "1         610\n",
       "6         180\n",
       "8          84\n",
       "7          80\n",
       "10         78\n",
       "9          34\n",
       "18         25\n",
       "14         25\n",
       "11         18\n",
       "12         13\n",
       "21         10\n",
       "15          4\n",
       "20          2\n",
       "16          1\n",
       "13          1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando a distribuição de faixas\n",
    "\n",
    "newdf['lanes'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72cf5e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "maxspeed\n",
       "110     25011\n",
       "120     14464\n",
       "100     13375\n",
       "80       6410\n",
       "90       4813\n",
       "60       2851\n",
       "None     2471\n",
       "50       1839\n",
       "70       1079\n",
       "40        673\n",
       "30          8\n",
       "20          2\n",
       "45          2\n",
       "35          2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando a distribuição de limites de velocidade\n",
    "\n",
    "newdf['maxspeed'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ff3ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo dados gerados com infraestrutura incompleta\n",
    "\n",
    "columns_dropna = ['oneway', 'lanes', 'maxspeed']\n",
    "\n",
    "newdf = newdf.dropna(subset=columns_dropna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f248e685",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arthur Rios\\AppData\\Local\\Temp\\ipykernel_6048\\2687004307.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  newdf['oneway'] = newdf['oneway'].replace('no', 0)\n"
     ]
    }
   ],
   "source": [
    "# Convertendo mão única para binário nos dados sintéticos\n",
    "\n",
    "newdf['oneway'] = newdf['oneway'].replace('yes', 1)\n",
    "\n",
    "newdf['oneway'] = newdf['oneway'].replace('no', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c84212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertendo colunas para inteiro\n",
    "\n",
    "newdf['oneway'] = newdf['oneway'].astype('int')\n",
    "newdf['lanes'] = newdf['lanes'].astype('int')\n",
    "newdf['maxspeed'] = newdf['maxspeed'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c811979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrando outliers de faixas\n",
    "\n",
    "mask = newdf['lanes'] > 8\n",
    "\n",
    "newdf = newdf[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceddab00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padronizando velocidades quebradas\n",
    "\n",
    "to_replace = [35, 45]\n",
    "value = [30, 40]\n",
    "\n",
    "newdf['maxspeed'] = newdf['maxspeed'].replace(value=value, to_replace=to_replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1cdf92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bridge\n",
       "None       66743\n",
       "yes         1225\n",
       "viaduct      557\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando distribuição de pontes\n",
    "\n",
    "newdf['bridge'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40460fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arthur Rios\\AppData\\Local\\Temp\\ipykernel_6048\\3072185598.py:5: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  newdf['bridge'] = newdf['bridge'].replace('viaduct', 1)\n"
     ]
    }
   ],
   "source": [
    "# Padronizando classificação de pontes e viadutos\n",
    "\n",
    "newdf['bridge'] = newdf['bridge'].fillna(0)\n",
    "\n",
    "newdf['bridge'] = newdf['bridge'].replace('yes', 1)\n",
    "\n",
    "newdf['bridge'] = newdf['bridge'].replace('viaduct', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48442104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertendo pontes para inteiro\n",
    "\n",
    "newdf['bridge'] = newdf['bridge'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29f9f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arthur Rios\\AppData\\Local\\Temp\\ipykernel_6048\\4084116460.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  newdf['highway'] = newdf['highway'].replace('trunk', 0)\n"
     ]
    }
   ],
   "source": [
    "# Convertendo tipo de rodovia para binário\n",
    "\n",
    "newdf['highway'] = newdf['highway'].replace('motorway', 1)\n",
    "newdf['highway'] = newdf['highway'].replace('trunk', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30f2d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renomeando coluna para motorway\n",
    "\n",
    "newdf.rename(columns={'highway': 'motorway'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a933e121",
   "metadata": {},
   "outputs": [],
   "source": [
    "#highways = newdf['highway'].unique()\n",
    "\n",
    "#for highway in highways:\n",
    "\n",
    "#    counts = newdf.loc[newdf['highway'] == highway, 'maxspeed'].value_counts(normalize=True)\n",
    "#    maxspeeds = counts.index\n",
    "#    prob = counts.values\n",
    "\n",
    "#    maxspeed_list = np.random.choice(\n",
    "#    a=maxspeeds,\n",
    "#    size=len(newdf[(newdf['highway'] == highway) & (newdf['maxspeed'].isnull())]),\n",
    "#    replace=True,\n",
    "#    p=prob\n",
    "#    )\n",
    "#\n",
    "#    newdf.loc[(newdf['highway'] == highway) & (newdf['maxspeed'].isnull()), 'maxspeed'] = maxspeed_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4203edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertendo dataframe original para GeoDataFrame para o spatial join reverso\n",
    "\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    df, \n",
    "    geometry=gpd.points_from_xy(df['longitude'], df['latitude']),\n",
    "    crs=\"EPSG:4326\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661e59b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizando spatial join para recuperar dados (concessionária/logradouro) dos pontos gerados\n",
    "\n",
    "gdf = gdf.to_crs(newdf.crs)\n",
    "\n",
    "datagendf = gpd.sjoin_nearest(\n",
    "    newdf,\n",
    "    gdf[['geometry', 'logradouro', 'concessionaria']], \n",
    "    how='left',\n",
    "    distance_col='dist_imprecision',\n",
    ")\n",
    "\n",
    "datagendf = datagendf.drop_duplicates(subset=['geometry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4d25c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    68525.000000\n",
       "mean       371.576135\n",
       "std        467.226136\n",
       "min          0.078350\n",
       "25%         63.127453\n",
       "50%        172.234736\n",
       "75%        452.550016\n",
       "max       2010.226541\n",
       "Name: dist_imprecision, dtype: float64"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analisando a precisão do join reverso\n",
    "\n",
    "datagendf['dist_imprecision'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d2e2cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "logradouro\n",
       "SP 330    15900\n",
       "SP 270    12820\n",
       "SP 310    11000\n",
       "SP 280    10526\n",
       "SP 070     7566\n",
       "SP 348     6397\n",
       "SP 150     3771\n",
       "SP 123      545\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando distribuição por rodovia nos dados sintéticos\n",
    "\n",
    "datagendf['logradouro'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a4d4cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "concessionaria\n",
       "DER                       20782\n",
       "AUTOBAN                    9472\n",
       "ECOPISTAS                  7566\n",
       "NAO DISPONIVEL             7462\n",
       "ECONOROESTE                5543\n",
       "CART                       4599\n",
       "SPVIAS                     2572\n",
       "EIXOSP - PIPA              1864\n",
       "ENTREVIAS                  1833\n",
       "ECOVIAS                    1514\n",
       "VIAOESTE                   1244\n",
       "INTERVIAS                  1102\n",
       "ROTA SOROCABANA            1012\n",
       "ECOVIAS RAPOSO-CASTELO      962\n",
       "COLINAS                     595\n",
       "VIAPAULISTA                 403\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando distribuição por concessionária nos dados sintéticos\n",
    "\n",
    "datagendf['concessionaria'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087b1884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['logradouro', 'latitude', 'longitude', 'concessionaria', 'hora', 'mes',\n",
       "       'dia_semana', 'indice_severidade', 'feriado', 'motorway', 'oneway',\n",
       "       'lanes', 'maxspeed', 'bridge', 'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conferindo colunas do dataset original\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0beff7e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['geometry', 'motorway', 'oneway', 'lanes', 'maxspeed', 'bridge',\n",
       "       'target', 'indice_severidade', 'dia_semana', 'mes', 'feriado', 'hora',\n",
       "       'index_right', 'logradouro', 'concessionaria', 'dist_imprecision'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conferindo colunas do dataset sintético\n",
    "\n",
    "datagendf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df39716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo colunas auxiliares antes da união\n",
    "\n",
    "df_drop_col = ['latitude', 'longitude']\n",
    "datagendf_drop_col = ['index_right', 'geometry', 'dist_imprecision']\n",
    "\n",
    "df = df.drop(df_drop_col, axis=1)\n",
    "datagendf = datagendf.drop(datagendf_drop_col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8bc81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenando dados reais e sintéticos\n",
    "\n",
    "df = pd.concat([df, datagendf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a09e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando One-Hot Encoding nas variáveis categóricas\n",
    "\n",
    "columns_encode = ['logradouro', 'concessionaria']\n",
    "\n",
    "df = pd.get_dummies(\n",
    "    data = df,\n",
    "    columns = columns_encode,\n",
    "    dtype=int\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e627b6d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['hora', 'mes', 'dia_semana', 'indice_severidade', 'feriado', 'motorway',\n",
       "       'oneway', 'lanes', 'maxspeed', 'bridge', 'target', 'logradouro_SP 070',\n",
       "       'logradouro_SP 123', 'logradouro_SP 150', 'logradouro_SP 270',\n",
       "       'logradouro_SP 280', 'logradouro_SP 310', 'logradouro_SP 330',\n",
       "       'logradouro_SP 348', 'concessionaria_AUTOBAN', 'concessionaria_CART',\n",
       "       'concessionaria_COLINAS', 'concessionaria_DER',\n",
       "       'concessionaria_ECONOROESTE', 'concessionaria_ECOPISTAS',\n",
       "       'concessionaria_ECOVIAS', 'concessionaria_ECOVIAS RAPOSO-CASTELO',\n",
       "       'concessionaria_EIXOSP - PIPA', 'concessionaria_ENTREVIAS',\n",
       "       'concessionaria_INTERVIAS', 'concessionaria_NAO DISPONIVEL',\n",
       "       'concessionaria_ROTA SOROCABANA', 'concessionaria_SPVIAS',\n",
       "       'concessionaria_VIAOESTE', 'concessionaria_VIAPAULISTA'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando estrutura final das colunas\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8c29e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91099, 35)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando dimensão final do dataset pronto para modelagem\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cb7740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando o arquivo final processado\n",
    "\n",
    "df.to_csv('data_machine_learning.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
